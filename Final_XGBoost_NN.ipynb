{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "seed= 7\n",
    "np.seed= seed\n",
    "import gc\n",
    "import importlib\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "\n",
    "# visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set(style=\"whitegrid\", font_scale= 1.5)\n",
    "from IPython.display import display\n",
    "\n",
    "# modelling\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Neural Networks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= '/kaggle/input/census_income_data.csv'\n",
    "data= pd.read_csv(path)\n",
    "\n",
    "print('data shape: ', data.shape)\n",
    "display(data.head())\n",
    "display(data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**splitting the data into train and test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= data.loc[ (data['income']== ' <=50K') | (data['income']== ' >50K') ]\n",
    "print('train shape: ', train.shape)\n",
    "\n",
    "test= data.loc[ ~ data.index.isin(train.index) ]\n",
    "# ignore the output column\n",
    "# we save the output column in y_test\n",
    "y_test= test.copy().iloc[:, -1]\n",
    "# but we can also dummy encode the variable\n",
    "y_test= y_test.apply(lambda x: 1 if x==' >50K.' else 0 )\n",
    "\n",
    "test= test.iloc[:, :-1] \n",
    "print('test shape: ', test.shape)\n",
    "\n",
    "# we also correct the indices of both train and test data\n",
    "train.index= range(len(train))\n",
    "test.index= range(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display( train.head(1) )\n",
    "#display( test.head(1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General Feature Engineering**\n",
    "\n",
    "1.`Combing both train and test so feature engineering is applied to both\n",
    "\n",
    "2. Label Ecndoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine both so the feature engineering is applied once\n",
    "\n",
    "df= pd.concat( [train, test], sort= False)\n",
    "df.index= range(len(df))\n",
    "\n",
    "# label encode\n",
    "cat_features= ['workclass', 'education',  'marital_status', 'occupation', 'relationship', 'race', \n",
    "               'sex', 'native_country']\n",
    "\n",
    "enc= LabelEncoder()\n",
    "for col in cat_features:\n",
    "    df[col]= enc.fit_transform( df[col])\n",
    "\n",
    "df['income']= df['income'].apply( lambda x: 1 if x==' >50K' else 0)\n",
    "\n",
    "# make sure all the features are of type float except the response variable!\n",
    "for col in df.columns[:-1]:\n",
    "    df[col]= df[col].astype(float)\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Engineering Schemes**\n",
    "\n",
    "1. Drop variable **fnlwgt**\n",
    "\n",
    "2. Get the feature importance based on the XGBoost model\n",
    "\n",
    "3. Based on the feature importance, build cartesian product of categorical features or drop some features and check for performance improvement\n",
    "\n",
    "\n",
    "**train test split again and saving the results to be run on kaggle engine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop= ['fnlwgt', 'income']\n",
    "X_train= df.iloc[ :len(train), :].drop(columns= to_drop).values\n",
    "y_train= df['income'].iloc[ :len(train)].values\n",
    "X_test= df.iloc[ len(train):, :].drop(columns= to_drop) .values\n",
    "y_test= y_test.values\n",
    "# we already have y_test\n",
    "features= list(df.columns)\n",
    "for col in to_drop:\n",
    "    features.remove(col)\n",
    "\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_test shape: ', y_test.shape)\n",
    "print('features: ', features )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_xgboost(X, y, init_params, tuning_params, metric= 'auc', cv= 5, seed= 42):\n",
    "    \"\"\"\n",
    "    fits XGboost model on a dataset\n",
    "    Arguments:\n",
    "        1. X: X_train, numpy array\n",
    "        2. y: y_train, numpy array\n",
    "        3. init_params: initial parameters as a dictionary to start \n",
    "            For ex. \n",
    "            init_params = {\n",
    "                'eta':0.2,\n",
    "                'max_depth': 8,\n",
    "                'min_child_weight': 3,\n",
    "                'colsample_bytree': 0.8,\n",
    "                'subsample': 0.8,\n",
    "                'gamma': 0, \n",
    "                'reg_lambda': 1,\n",
    "                'reg_alpha': 0,\n",
    "                'scale_pos_weight': 3.15,\n",
    "                'objective':'binary:logistic'}\n",
    "        4. tuning_params: a dictionary of tuples, where the key shows the parameter to be\n",
    "            changed for gridsearch and the value shows the possible values as a list.\n",
    "            list because of gridsearch\n",
    "        5. cv: number of folds\n",
    "    \"\"\"\n",
    "    # find pos_weight: num(zeros)/ num(ones)\n",
    "    counts= pd.Series(y_train).value_counts()\n",
    "    pos_weight= np.round(counts.loc[0] / counts.loc[1], 2 )\n",
    "    # change scale_pos_weight\n",
    "    init_params['scale_pos_weight']= pos_weight\n",
    "    \n",
    "    # build dataset special for xgboost \n",
    "    dtrain = xgb.DMatrix(X_train, label= y_train)\n",
    "    \n",
    "    # find initial number of trees for a set of initial parameters\n",
    "    print('Finding the initial number of trees with the initial parameters...')\n",
    "    cv_results = xgb.cv( init_params, \n",
    "                         dtrain,  \n",
    "                         num_boost_round= 1000, \n",
    "                         seed= seed, \n",
    "                         nfold= cv, \n",
    "                         stratified= True,\n",
    "                         metrics= {metric},   \n",
    "                         early_stopping_rounds= 50)\n",
    "    ntrees= len(cv_results)\n",
    "    print('The initial number of trees is %d' %ntrees)\n",
    "    print('*'*10)\n",
    "    \n",
    "    # fixing randomness\n",
    "    np.random.seed(seed)\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    \n",
    "    def XGB_gridsearch(X1, y1, estimator, params, cv= cv ):\n",
    "        \"\"\"\n",
    "        After finding the initial number of trees to start with, we have to adjust other hyper-\n",
    "        parameters as explained before with gridsearch\n",
    "        ARguments:\n",
    "            X1: X_train, numpy array\n",
    "            y1: y_train, numpy array\n",
    "            cv: number of cv folds, int\n",
    "            params: parameters for gridsearch, dictionary with the following keys\n",
    "                ex.\n",
    "                parameters = {\n",
    "                'n_estimators': n_estimators,\n",
    "                'learning_rate': learning_rate,\n",
    "                'max_depth': max_depth,\n",
    "                'min_child_weight': min_child_weight,\n",
    "                'gamma': gamma,\n",
    "                'colsample_bytree': colsample_bytree,\n",
    "                'subsample': subsample,\n",
    "                'reg_lambda': reg_lambda,\n",
    "                'reg_alpha': reg_alpha,\n",
    "                'scale_pos_weight': scale_pos_weight,\n",
    "                'objective': ['binary:logistic'] }\n",
    "        \"\"\"\n",
    "        # There is not a match between gridsearchcv scoring naming and that of xgboost naming\n",
    "        if metric== 'auc':\n",
    "            scoring = 'roc_auc'\n",
    "            grid_search = GridSearchCV(estimator = estimator, param_grid = params, \n",
    "                                 scoring= scoring, cv = cv, n_jobs= -1, verbose = 2)\n",
    "        else:\n",
    "            grid_search = GridSearchCV(estimator = estimator, param_grid = params, \n",
    "                                 scoring= metric, cv = cv, n_jobs= -1, verbose = 2)\n",
    "        grid_search.fit(X1, y1)\n",
    "\n",
    "        return grid_search.best_estimator_, grid_search.best_params_, grid_search.best_score_\n",
    "    ##############################################\n",
    "    # This is a base estimator for grid search\n",
    "    xgb_clf= xgb.XGBClassifier(random_state= seed )\n",
    "    \n",
    "    # essentially it is the same as init_params but with one extra key n_estimators\n",
    "    # besides, the values are in form of a list because we are grid searching\n",
    "    parameters= init_params\n",
    "    # change eta into learning rate\n",
    "    parameters['learning_rate']= parameters['eta']; del(parameters['eta'])\n",
    "    # add n_estimators\n",
    "    parameters['n_estimators']= ntrees\n",
    "    # convert values into lists\n",
    "    for k, v in parameters.items():\n",
    "            parameters[k]= [ v ]\n",
    "    \n",
    "    tuning_order= [ ['max_depth', 'min_child_weight'], ['gamma'], \n",
    "                   [ 'colsample_bytree', 'subsample'], ['reg_lambda'], ['reg_alpha'] ]\n",
    "    for stage in tuning_order:\n",
    "        for el in stage:\n",
    "            parameters[el]= tuning_params[el]\n",
    "        \n",
    "        print('grid-searching for \" %s \"' %str(stage))\n",
    "        #import pdb; pdb.set_trace()\n",
    "        model= XGB_gridsearch(X1= X, y1= y, estimator= xgb_clf, cv= cv, params= parameters )\n",
    "        updated_params= model[1]\n",
    "        updated_score= model[2]\n",
    "        \n",
    "        for el in stage:\n",
    "            parameters[el]= [ updated_params[el] ]\n",
    "            \n",
    "        print('updated parameters...')\n",
    "        print('The current score for metric \"%s\" is: %0.4f ' %( metric, updated_score) )\n",
    "        print('*'*10)\n",
    "    \n",
    "    print('Found all the hyperparameters for the initial number of trees: ntrees= %d' %ntrees)\n",
    "    hyperparameters= parameters\n",
    "    for k,v in hyperparameters.items():\n",
    "        hyperparameters[k]= v[0] # delisting\n",
    "        \n",
    "    print('Now we will start the process of learning by the found hyperparameters and by \\\n",
    "considering a low learning rate\\n')\n",
    "    \n",
    "    hyperparameters['eta']= 0.01\n",
    "    del(hyperparameters['learning_rate'], hyperparameters['n_estimators'])\n",
    "    \n",
    "    cv_results = xgb.cv( hyperparameters, \n",
    "                     dtrain,  \n",
    "                     num_boost_round= 3000, \n",
    "                     seed= seed, \n",
    "                     nfold= cv, \n",
    "                     stratified= True,\n",
    "                     metrics= { metric },   \n",
    "                     early_stopping_rounds= 100)\n",
    "    print('The optimum number of trees is: %d' %len(cv_results))\n",
    "    print('train score for metric \"%s\" is: %0.04f' % (metric, cv_results.iloc[-1, 0]))\n",
    "    print('test score for metric \"%s\" is: %0.04f' % (metric, cv_results.iloc[-1, 2]))\n",
    "    \n",
    "    # prepare for output\n",
    "    hyperparameters['learning_rate']= 0.01; del(hyperparameters['eta'])\n",
    "    hyperparameters['n_estimators']= len(cv_results)\n",
    "    print('The best hyperparameters are: \\n')\n",
    "    print(hyperparameters)\n",
    "    return hyperparameters, cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start= time.time()\n",
    "\n",
    "hyperparameters, cv_results= fit_xgboost(X_train, y_train, init_params= {\n",
    "                'eta':0.2,\n",
    "                'max_depth': 8,\n",
    "                'min_child_weight': 3,\n",
    "                'colsample_bytree': 0.8,\n",
    "                'subsample': 0.8,\n",
    "                'gamma': 0, \n",
    "                'reg_lambda': 1,\n",
    "                'reg_alpha': 0,\n",
    "                'scale_pos_weight': 3.15,\n",
    "                'objective':'binary:logistic'}, \n",
    "                tuning_params= {\n",
    "                'learning_rate': [0.2],\n",
    "                'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                'min_child_weight': [1, 2, 3, 4, 5],\n",
    "                'colsample_bytree': [i/10.0 for i in range(4,10)],\n",
    "                'subsample': [i/10.0 for i in range(6,10)],\n",
    "                'gamma': [i/10.0 for i in range(0,5)], \n",
    "                'reg_lambda': [1e-5, 1e-2, 0.1, 1, 10, 100],\n",
    "                'reg_alpha': [1e-5, 1e-2, 0.1, 1, 10, 100],\n",
    "                'scale_pos_weight': [3.15],\n",
    "                'objective': ['binary:logistic']}, metric= 'auc', cv= 5, seed= 42\n",
    "           )\n",
    "\n",
    "print('\\n\\nThe runtime took %.2f seconds.' %( time.time() - start ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cv_results.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit a XGBoost model with the scikit-learn wrapper of XGBoost and the found hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf= xgb.XGBClassifier( random_state= seed,  **hyperparameters )\n",
    "xgb_clf.fit(X_train, y_train,\n",
    "                   eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "                   eval_metric= 'auc',\n",
    "                   #early_stopping_rounds= 100, \n",
    "                   verbose= False)\n",
    "evals_result = xgb_clf.evals_result()\n",
    "\n",
    "evals_result= pd.DataFrame( {'train_auc': evals_result['validation_0']['auc'], \n",
    "              'test_auc': evals_result['validation_1']['auc']} )\n",
    "display(evals_result.head())\n",
    "display(evals_result.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (10, 5))\n",
    "plt.plot( evals_result['train_auc'], label= 'train_auc')\n",
    "plt.plot( evals_result['test_auc'], label= 'real_test_auc')\n",
    "plt.plot( cv_results['test-auc-mean'], label= 'cv_auc')\n",
    "plt.xlabel('number of trees')\n",
    "plt.ylabel('roc_auc')\n",
    "plt.title('fnlwgt dropped!')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= xgb_clf.predict(X_train)\n",
    "print('Confusion matrix for he train data')\n",
    "display( confusion_matrix(y_pred, y_train) )\n",
    "\n",
    "y_test_pred= xgb_clf.predict(X_test)\n",
    "print('Confusion matrix for the test data')\n",
    "display( confusion_matrix(y_test_pred, y_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_importance= list( zip( features, xgb_clf.feature_importances_) )\n",
    "features_importance= sorted(features_importance, key= lambda x: x[1], reverse= True)\n",
    "\n",
    "plt.figure(figsize= (10,5))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(len(features)), [el[1] for el in features_importance],  color=\"r\",  align=\"center\")\n",
    "plt.xticks(range(len(features)), [el[0] for el in features_importance], rotation= 90)\n",
    "plt.xlim([-1, len(features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# more feature engineering ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartesian(df, col1, col2):\n",
    "    \"\"\"\n",
    "    The cartesian product of two categorical columns from a dataframe is calculated and returned as a \n",
    "    Pandas Series\n",
    "    \"\"\"\n",
    "    \n",
    "    temp= df[col1].astype(str).apply(lambda x: '(' + x ) + ', ' +  df[col2].astype(str).\\\n",
    "                                                    apply(lambda y: y + ')' )\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# add features\n",
    "df['rms']= cartesian(df, 'relationship', 'marital_status')\n",
    "# label encode it\n",
    "enc= LabelEncoder()\n",
    "df['rms']= enc.fit_transform( df['rms'])\"\"\"\n",
    "\n",
    "# we already have y_train and y_test\n",
    "# we just drop the columns we don't want \n",
    "to_drop= ['fnlwgt', 'income', 'marital_status']\n",
    "X_train= df.iloc[ :len(train), :].drop(columns= to_drop).values\n",
    "X_test= df.iloc[ len(train):, :].drop(columns= to_drop) .values\n",
    "features= list(df.columns)\n",
    "for col in to_drop:\n",
    "    features.remove(col)\n",
    "    \n",
    "\n",
    "\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_test shape: ', y_test.shape)\n",
    "print('features: ', features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start= time.time()\n",
    "\n",
    "hyperparameters, cv_results= fit_xgboost(X_train, y_train, init_params= {\n",
    "                'eta':0.2,\n",
    "                'max_depth': 8,\n",
    "                'min_child_weight': 3,\n",
    "                'colsample_bytree': 0.8,\n",
    "                'subsample': 0.8,\n",
    "                'gamma': 0, \n",
    "                'reg_lambda': 1,\n",
    "                'reg_alpha': 0,\n",
    "                'scale_pos_weight': 3.15,\n",
    "                'objective':'binary:logistic'}, \n",
    "                tuning_params= {\n",
    "                'learning_rate': [0.2],\n",
    "                'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                'min_child_weight': [1, 2, 3, 4, 5],\n",
    "                'colsample_bytree': [i/10.0 for i in range(4,10)],\n",
    "                'subsample': [i/10.0 for i in range(6,10)],\n",
    "                'gamma': [i/10.0 for i in range(0,5)], \n",
    "                'reg_lambda': [1e-5, 1e-2, 0.1, 1, 10, 100],\n",
    "                'reg_alpha': [1e-5, 1e-2, 0.1, 1, 10, 100],\n",
    "                'scale_pos_weight': [3.15],\n",
    "                'objective': ['binary:logistic']}, metric= 'auc', cv= 5, seed= 42\n",
    "           )\n",
    "\n",
    "print('\\n\\nThe runtime took %.2f seconds.' %( time.time() - start ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf= xgb.XGBClassifier( random_state= seed,  **hyperparameters )\n",
    "xgb_clf.fit(X_train, y_train,\n",
    "                   eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "                   eval_metric= 'auc',\n",
    "                   #early_stopping_rounds= 100, \n",
    "                   verbose= False)\n",
    "evals_result = xgb_clf.evals_result()\n",
    "\n",
    "evals_result= pd.DataFrame( {'train_auc': evals_result['validation_0']['auc'], \n",
    "              'test_auc': evals_result['validation_1']['auc']} )\n",
    "display(evals_result.head())\n",
    "display(evals_result.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (10, 5))\n",
    "plt.plot( evals_result['train_auc'], label= 'train_auc')\n",
    "plt.plot( evals_result['test_auc'], label= 'real_test_auc')\n",
    "plt.plot( cv_results['test-auc-mean'], label= 'cv_auc')\n",
    "plt.xlabel('number of trees')\n",
    "plt.ylabel('roc_auc')\n",
    "plt.title('fnlwgt dropped!')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred= xgb_clf.predict(X_test)\n",
    "confusion_matrix(y_test_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_importance= list( zip( features, xgb_clf.feature_importances_) )\n",
    "features_importance= sorted(features_importance, key= lambda x: x[1], reverse= True)\n",
    "\n",
    "plt.figure(figsize= (10,5))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(len(features)), [el[1] for el in features_importance],  color=\"r\",  align=\"center\")\n",
    "plt.xticks(range(len(features)), [el[0] for el in features_importance], rotation= 90)\n",
    "plt.xlim([-1, len(features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost with dummy encoding of the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine both so the feature engineering is applied once\n",
    "\n",
    "df_dummy= pd.concat( [train, test], sort= False)\n",
    "df_dummy.index= range(len(df_dummy))\n",
    "\n",
    "# label encode\n",
    "cat_features= ['workclass', 'education',  'marital_status', 'occupation', 'relationship', 'race', \n",
    "               'sex', 'native_country']\n",
    "\n",
    "for col in cat_features:\n",
    "    df_temp= pd.get_dummies(df_dummy[col])\n",
    "    # change the column names\n",
    "    df_temp.columns= [col+'_'+el for el in df_temp.columns]\n",
    "    # drop the original column\n",
    "    df_dummy.drop(columns= col, inplace= True)\n",
    "    # add the newly obtained columns to df\n",
    "    df_dummy= pd.concat( [df_dummy, df_temp], axis= 1)\n",
    "\n",
    "\n",
    "df_dummy['income']= df_dummy['income'].apply( lambda x: 1 if x==' >50K' else 0)\n",
    "\n",
    "display(df_dummy.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we already have y_train and y_test\n",
    "# we just drop the columns we don't want \n",
    "to_drop= ['fnlwgt', 'income']\n",
    "X_train= df_dummy.iloc[ :len(train), :].drop(columns= to_drop).values\n",
    "X_test= df_dummy.iloc[ len(train):, :].drop(columns= to_drop) .values\n",
    "features= list(df_dummy.columns)\n",
    "for col in to_drop:\n",
    "    features.remove(col)\n",
    "    \n",
    "\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_test shape: ', y_test.shape)\n",
    "print('features: ', features )\n",
    "###################################################################\n",
    "start= time.time()\n",
    "\n",
    "hyperparameters, cv_results= fit_xgboost(X_train, y_train, init_params= {\n",
    "                'eta':0.2,\n",
    "                'max_depth': 8,\n",
    "                'min_child_weight': 3,\n",
    "                'colsample_bytree': 0.8,\n",
    "                'subsample': 0.8,\n",
    "                'gamma': 0, \n",
    "                'reg_lambda': 1,\n",
    "                'reg_alpha': 0,\n",
    "                'scale_pos_weight': 3.15,\n",
    "                'objective':'binary:logistic'}, \n",
    "                tuning_params= {\n",
    "                'learning_rate': [0.2],\n",
    "                'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                'min_child_weight': [1, 2, 3, 4, 5],\n",
    "                'colsample_bytree': [i/10.0 for i in range(4,10)],\n",
    "                'subsample': [i/10.0 for i in range(6,10)],\n",
    "                'gamma': [i/10.0 for i in range(0,5)], \n",
    "                'reg_lambda': [1e-5, 1e-2, 0.1, 1, 10, 100],\n",
    "                'reg_alpha': [1e-5, 1e-2, 0.1, 1, 10, 100],\n",
    "                'scale_pos_weight': [3.15],\n",
    "                'objective': ['binary:logistic']}, metric= 'auc', cv= 5, seed= 42\n",
    "           )\n",
    "\n",
    "print('\\n\\nThe runtime took %.2f seconds.' %( time.time() - start ) )\n",
    "#############################################################\n",
    "xgb_clf= xgb.XGBClassifier( random_state= seed,  **hyperparameters )\n",
    "xgb_clf.fit(X_train, y_train,\n",
    "                   eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "                   eval_metric= 'auc',\n",
    "                   #early_stopping_rounds= 100, \n",
    "                   verbose= False)\n",
    "evals_result = xgb_clf.evals_result()\n",
    "\n",
    "evals_result= pd.DataFrame( {'train_auc': evals_result['validation_0']['auc'], \n",
    "              'test_auc': evals_result['validation_1']['auc']} )\n",
    "display(evals_result.head())\n",
    "display(evals_result.tail())\n",
    "#############################################################\n",
    "plt.figure(figsize= (10, 5))\n",
    "plt.plot( evals_result['train_auc'], label= 'train_auc')\n",
    "plt.plot( evals_result['test_auc'], label= 'real_test_auc')\n",
    "plt.plot( cv_results['test-auc-mean'], label= 'cv_auc')\n",
    "plt.xlabel('number of trees')\n",
    "plt.ylabel('roc_auc')\n",
    "plt.title('fnlwgt dropped!')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_importance= list( zip( features, xgb_clf.feature_importances_) )\n",
    "features_importance= sorted(features_importance, key= lambda x: x[1], reverse= True)\n",
    "\n",
    "plt.figure(figsize= (50,5))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(len(features)), [el[1] for el in features_importance],  color=\"r\",  align=\"center\")\n",
    "plt.xticks(range(len(features)), [el[0] for el in features_importance], rotation= 90)\n",
    "plt.xlim([-1, len(features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= xgb_clf.predict(X_train)\n",
    "print('Confusion matrix for he train data')\n",
    "display( confusion_matrix(y_pred, y_train) )\n",
    "\n",
    "y_test_pred= xgb_clf.predict(X_test)\n",
    "print('Confusion matrix for the test data')\n",
    "display( confusion_matrix(y_test_pred, y_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature selection from dummy-encoded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(features_importance[:5])\n",
    "display(features_importance[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we already have y_train and y_test\n",
    "# we just drop the columns we don't want \n",
    "dummy_drop= [ el[0] for el in features_importance if el[1] == 0 ]\n",
    "to_drop= ['fnlwgt', 'income'] + dummy_drop\n",
    "X_train= df_dummy.iloc[ :len(train), :].drop(columns= to_drop).values\n",
    "X_test= df_dummy.iloc[ len(train):, :].drop(columns= to_drop) .values\n",
    "features= list(df_dummy.columns)\n",
    "for col in to_drop:\n",
    "    features.remove(col)\n",
    "    \n",
    "\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_test shape: ', y_test.shape)\n",
    "print('features: ', features )\n",
    "###################################################################\n",
    "start= time.time()\n",
    "\n",
    "hyperparameters, cv_results= fit_xgboost(X_train, y_train, init_params= {\n",
    "                'eta':0.2,\n",
    "                'max_depth': 8,\n",
    "                'min_child_weight': 3,\n",
    "                'colsample_bytree': 0.8,\n",
    "                'subsample': 0.8,\n",
    "                'gamma': 0, \n",
    "                'reg_lambda': 1,\n",
    "                'reg_alpha': 0,\n",
    "                'scale_pos_weight': 3.15,\n",
    "                'objective':'binary:logistic'}, \n",
    "                tuning_params= {\n",
    "                'learning_rate': [0.2],\n",
    "                'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                'min_child_weight': [1, 2, 3, 4, 5],\n",
    "                'colsample_bytree': [i/10.0 for i in range(4,10)],\n",
    "                'subsample': [i/10.0 for i in range(6,10)],\n",
    "                'gamma': [i/10.0 for i in range(0,5)], \n",
    "                'reg_lambda': [1e-5, 1e-2, 0.1, 1, 10, 100],\n",
    "                'reg_alpha': [1e-5, 1e-2, 0.1, 1, 10, 100],\n",
    "                'scale_pos_weight': [3.15],\n",
    "                'objective': ['binary:logistic']}, metric= 'auc', cv= 5, seed= 42\n",
    "           )\n",
    "\n",
    "print('\\n\\nThe runtime took %.2f seconds.' %( time.time() - start ) )\n",
    "#############################################################\n",
    "xgb_clf= xgb.XGBClassifier( random_state= seed,  **hyperparameters )\n",
    "xgb_clf.fit(X_train, y_train,\n",
    "                   eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "                   eval_metric= 'auc',\n",
    "                   #early_stopping_rounds= 100, \n",
    "                   verbose= False)\n",
    "evals_result = xgb_clf.evals_result()\n",
    "\n",
    "evals_result= pd.DataFrame( {'train_auc': evals_result['validation_0']['auc'], \n",
    "              'test_auc': evals_result['validation_1']['auc']} )\n",
    "display(evals_result.head())\n",
    "display(evals_result.tail())\n",
    "#############################################################\n",
    "plt.figure(figsize= (10, 5))\n",
    "plt.plot( evals_result['train_auc'], label= 'train_auc')\n",
    "plt.plot( evals_result['test_auc'], label= 'real_test_auc')\n",
    "plt.plot( cv_results['test-auc-mean'], label= 'cv_auc')\n",
    "plt.xlabel('number of trees')\n",
    "plt.ylabel('roc_auc')\n",
    "plt.title('fnlwgt dropped!')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= xgb_clf.predict(X_train)\n",
    "print('Confusion matrix for he train data')\n",
    "display( confusion_matrix(y_pred, y_train) )\n",
    "\n",
    "y_test_pred= xgb_clf.predict(X_test)\n",
    "print('Confusion matrix for the test data')\n",
    "display( confusion_matrix(y_test_pred, y_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel= 'normal'\n",
    "\n",
    "def create_baseline():\n",
    "    model= Sequential()\n",
    "    model.add( Dense(92, input_dim= 92, kernel_initializer= kernel, activation= 'relu'))\n",
    "    model.add( Dense(92, kernel_initializer= kernel, activation= 'relu'))\n",
    "    model.add( Dense(92, kernel_initializer= kernel, activation= 'relu'))\n",
    "    model.add( Dense(46, kernel_initializer= kernel, activation= 'relu'))\n",
    "    model.add( Dense(23, kernel_initializer= kernel, activation= 'relu'))\n",
    "    model.add( Dense(1, kernel_initializer= kernel, activation= 'sigmoid' ) )\n",
    "    \n",
    "    model.compile(loss= 'binary_crossentropy', optimizer= 'adam', metrics= [ tf.keras.metrics.AUC() ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).value_counts(normalize= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start= time.time()\n",
    "# train test error\n",
    "model= create_baseline()\n",
    "history= model.fit(X_train, y_train, epochs= 1200, batch_size= 512, validation_data= (X_test, y_test) ) \n",
    "                                               # class_weight= {0: 1, 1: 76.3/23.6} )\n",
    "\n",
    "print(\"Training the neural network took %.1f seconds.\" %( time.time() - start ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**plot auc developement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (20, 4))\n",
    "plt.ylim(0, 1)\n",
    "plt.plot(history.history['auc_14'], )\n",
    "plt.plot(history.history['val_auc_14'], marker= 'o', markersize= 4)\n",
    "plt.title('model auc')\n",
    "plt.ylabel('auc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**plotting the loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (20, 4))\n",
    "#plt.ylim(0, 1)\n",
    "plt.plot(history.history['loss'], )\n",
    "plt.plot(history.history['val_loss'], marker= 'o', markersize= 4)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred= model.predict_classes(X_test)  \n",
    "#pd.Series(y_test_pred.ravel()).value_counts()\n",
    "matrix = confusion_matrix(y_test, y_test_pred)\n",
    "matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= model.predict_classes(X_train)  \n",
    "matrix = confusion_matrix(y_train, y_pred)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred= pd.Series(model.predict(X_test).ravel() )\n",
    "y_test_pred= y_test_pred.apply(lambda x: 1 if x>= 0.2 else 0)\n",
    "matrix = confusion_matrix(y_test, y_test_pred)\n",
    "matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
